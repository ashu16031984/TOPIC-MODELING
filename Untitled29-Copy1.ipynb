{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea80091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding admission\\n/waiting time/ bed availa...</td>\n",
       "      <td>When I entered this hospital, there was a long...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waiting time\\nPatient load\\nQueue\\nDischarge r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regarding admission\\n/waiting time/ bed availa...</td>\n",
       "      <td>Admission is easily .But doctors come very lat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regarding admission\\n/waiting time/ bed availa...</td>\n",
       "      <td>When I enter the hospital are very waiting but...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regarding admission\\n/waiting time/ bed availa...</td>\n",
       "      <td>Availability very best  easily bed. For coming...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regarding admission\\n/waiting time/ bed availa...</td>\n",
       "      <td>When I entered in this hospital .I couldn't fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  Regarding admission\\n/waiting time/ bed availa...   \n",
       "1  Regarding admission\\n/waiting time/ bed availa...   \n",
       "2  Regarding admission\\n/waiting time/ bed availa...   \n",
       "3  Regarding admission\\n/waiting time/ bed availa...   \n",
       "4  Regarding admission\\n/waiting time/ bed availa...   \n",
       "\n",
       "                                             Comment  Unnamed: 2  Unnamed: 3  \\\n",
       "0  When I entered this hospital, there was a long...         NaN         NaN   \n",
       "1  Admission is easily .But doctors come very lat...         NaN         NaN   \n",
       "2  When I enter the hospital are very waiting but...         NaN         NaN   \n",
       "3  Availability very best  easily bed. For coming...         NaN         NaN   \n",
       "4  When I entered in this hospital .I couldn't fi...         NaN         NaN   \n",
       "\n",
       "                                          Unnamed: 4  \n",
       "0  Waiting time\\nPatient load\\nQueue\\nDischarge r...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('..')\n",
    "# Read data into papers\n",
    "#\"C:\\Users\\ashut\\Downloads\\Regarding_admission.csv\"\n",
    "papers = papers = pd.read_csv(\"C:\\\\Users\\\\ashut\\\\Downloads\\\\Regarding_admission.csv\",encoding='latin1')\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a511dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I entered this hospital, there was a long...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waiting time\\nPatient load\\nQueue\\nDischarge r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission is easily .But doctors come very lat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I enter the hospital are very waiting but...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Availability very best  easily bed. For coming...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I entered in this hospital .I couldn't fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Patients appreciate the hassle-free registrati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>The hospital is vigilant about not exceeding i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Implementing an effective admission process he...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>The streamlined registration system has signif...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>A focus on treatment quality directly contribu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment  Unnamed: 2  \\\n",
       "0    When I entered this hospital, there was a long...         NaN   \n",
       "1    Admission is easily .But doctors come very lat...         NaN   \n",
       "2    When I enter the hospital are very waiting but...         NaN   \n",
       "3    Availability very best  easily bed. For coming...         NaN   \n",
       "4    When I entered in this hospital .I couldn't fi...         NaN   \n",
       "..                                                 ...         ...   \n",
       "209  Patients appreciate the hassle-free registrati...         NaN   \n",
       "210  The hospital is vigilant about not exceeding i...         NaN   \n",
       "211  Implementing an effective admission process he...         NaN   \n",
       "212  The streamlined registration system has signif...         NaN   \n",
       "213  A focus on treatment quality directly contribu...         NaN   \n",
       "\n",
       "     Unnamed: 3                                         Unnamed: 4  \n",
       "0           NaN  Waiting time\\nPatient load\\nQueue\\nDischarge r...  \n",
       "1           NaN                                                NaN  \n",
       "2           NaN                                                NaN  \n",
       "3           NaN                                                NaN  \n",
       "4           NaN                                                NaN  \n",
       "..          ...                                                ...  \n",
       "209         NaN                                                NaN  \n",
       "210         NaN                                                NaN  \n",
       "211         NaN                                                NaN  \n",
       "212         NaN                                                NaN  \n",
       "213         NaN                                                NaN  \n",
       "\n",
       "[214 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = papers.drop(columns=['Questions'], axis=1)\n",
    "papers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cefd238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "#print(papers['Comment'].dtype)\n",
    "papers['Comment'] = papers['Comment'].astype(str)\n",
    "print(papers['Comment'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b96836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    when i entered this hospital there was a long ...\n",
       "1    admission is easily but doctors come very late...\n",
       "2    when i enter the hospital are very waiting but...\n",
       "3    availability very best  easily bed for coming ...\n",
       "4    when i entered in this hospital i couldn't fin...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "papers['paper_text_processed'] = papers[\"Comment\"].map(lambda x: re.sub('[,\\.\\!\\?]','', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers['paper_text_processed'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c84d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'entered', 'this', 'hospital', 'there', 'was', 'long', 'crew', 'waiting', 'time', 'is', 'the', 'big', 'problem', 'bed', 'is', 'not', 'available', 'all', 'the', 'time', 'it', 'should', 'be', 'minimized', 'it', 'is', 'the', 'duty', 'of']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499849ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=2, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=10)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf51cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','doctor','also','come','hospital','rim','take','find','do','good'])\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd83a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 40.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.11)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (22.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashut\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "['enter', 'long', 'crew', 'waiting_time', 'big', 'problem', 'bed', 'available', 'time', 'minimized', 'duty', 'give', 'proper', 'time', 'frustrate', 'patient', 'manage', 'patient_load', 'efficiently', 'provide', 'timely', 'carethe', 'commitment', 'maintain', 'low_morbidity', 'rate', 'evident', 'emphasis', 'treatment_quality', 'patient_care']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939cf5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e2871f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e87eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.043*\"treatment_quality\" + 0.042*\"rate\" + 0.039*\"low_morbidity\" + '\n",
      "  '0.034*\"long\" + 0.027*\"queue\" + 0.023*\"registration\" + 0.022*\"maintain\" + '\n",
      "  '0.017*\"effective\" + 0.013*\"patient\" + 0.013*\"time\"'),\n",
      " (1,\n",
      "  '0.093*\"admission\" + 0.047*\"bed_capacity\" + 0.038*\"discharge_rate\" + '\n",
      "  '0.037*\"time\" + 0.037*\"morbidity_rate\" + 0.036*\"treatment_quality\" + '\n",
      "  '0.035*\"registration_system\" + 0.031*\"bed\" + 0.024*\"wait\" + '\n",
      "  '0.023*\"bed_availability\"'),\n",
      " (2,\n",
      "  '0.031*\"registration\" + 0.028*\"time\" + 0.023*\"waiting_time\" + '\n",
      "  '0.019*\"bed_availability\" + 0.019*\"patient\" + 0.019*\"poor\" + '\n",
      "  '0.014*\"bed_capacity\" + 0.013*\"admission\" + 0.013*\"test\" + '\n",
      "  '0.013*\"availability\"'),\n",
      " (3,\n",
      "  '0.067*\"time\" + 0.055*\"queue_discharge\" + 0.055*\"rate_registration\" + '\n",
      "  '0.054*\"system_admission\" + 0.054*\"quality_morbidity\" + 0.053*\"bed_capacity\" '\n",
      "  '+ 0.041*\"patient_load\" + 0.030*\"bed\" + 0.026*\"long\" + 0.026*\"waiting_time\"'),\n",
      " (4,\n",
      "  '0.032*\"waiting_time\" + 0.029*\"queue\" + 0.028*\"long\" + 0.025*\"system\" + '\n",
      "  '0.021*\"registration\" + 0.019*\"admission\" + 0.017*\"bed_availability\" + '\n",
      "  '0.015*\"bed\" + 0.014*\"service\" + 0.014*\"doctor\"'),\n",
      " (5,\n",
      "  '0.023*\"crowd\" + 0.019*\"available\" + 0.016*\"bed\" + 0.016*\"system\" + '\n",
      "  '0.016*\"due\" + 0.016*\"proper\" + 0.016*\"decrease\" + 0.016*\"lot\" + '\n",
      "  '0.015*\"timewaiting_time\" + 0.015*\"enter\"'),\n",
      " (6,\n",
      "  '0.019*\"patient\" + 0.016*\"get\" + 0.014*\"bed\" + 0.014*\"morbidity_rate\" + '\n",
      "  '0.014*\"discharge_rate\" + 0.014*\"treatment_quality\" + 0.014*\"emergency\" + '\n",
      "  '0.013*\"queue_management\" + 0.013*\"enhance\" + 0.013*\"patient_experience\"'),\n",
      " (7,\n",
      "  '0.045*\"patient\" + 0.026*\"registration_system\" + 0.020*\"patient_load\" + '\n",
      "  '0.020*\"discharge_rate\" + 0.017*\"waiting_time\" + 0.013*\"overall\" + '\n",
      "  '0.013*\"bed_capacity\" + 0.013*\"morbidity_rate\" + 0.013*\"high\" + '\n",
      "  '0.013*\"essential\"'),\n",
      " (8,\n",
      "  '0.028*\"treatment_quality\" + 0.028*\"bed\" + 0.026*\"patient\" + '\n",
      "  '0.020*\"admission\" + 0.019*\"patient_experience\" + '\n",
      "  '0.019*\"registration_system\" + 0.017*\"availability\" + 0.017*\"overall\" + '\n",
      "  '0.015*\"system\" + 0.015*\"wait\"'),\n",
      " (9,\n",
      "  '0.042*\"admission\" + 0.034*\"enter\" + 0.029*\"bed_availability\" + 0.029*\"wait\" '\n",
      "  '+ 0.027*\"patient\" + 0.021*\"bed_capacity\" + 0.021*\"bed\" + 0.020*\"many\" + '\n",
      "  '0.019*\"waiting_time\" + 0.014*\"crowd\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfbdad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.4076969767202388\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c154d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                 | 100/540 [11:35<49:53,  6.80s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('C:\\\\Users\\\\ashut\\\\Downloads\\\\Result', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfd92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1237b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
